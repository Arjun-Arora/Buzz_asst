{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "X shape: (55000, 784)\n",
      "Y shape: (55000, 10)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f96804fb810>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "# print out shapes and example im\n",
    "print(\"X shape: {}\".format(mnist.train.images.shape))\n",
    "print(\"Y shape: {}\".format(mnist.train.labels.shape))\n",
    "n = 28\n",
    "n_classes = 10\n",
    "print()\n",
    "plt.imshow(mnist.train.images[4].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights and biases definition\n",
    "W = {'W_0': tf.get_variable('W0', shape=(3,3,1,16), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "       'W_1': tf.get_variable('W1', shape=(3,3,16,64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "       'W_2': tf.get_variable('W2', shape=(3,3,64,128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "       'W_3': tf.get_variable('W3', shape=(3,3,128,256), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "       'W_4': tf.get_variable('W4', shape=(256 * 2 * 2,128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "       'W_5': tf.get_variable('W5', shape=(128,n_classes), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "      }\n",
    "b = {'B_0': tf.get_variable('B0', shape=(16), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "       'B_1': tf.get_variable('B1', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "       'B_2': tf.get_variable('B2', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "       'B_3': tf.get_variable('B3', shape=(256), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "       'B_4': tf.get_variable('B4', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "       'B_5': tf.get_variable('B5', shape=(n_classes), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arjunarora/anaconda3/envs/verkada/lib/python3.7/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(Model,X,Y,lr = 0.001,batch_sz = 128,num_epochs = 100):\n",
    "    if len(X.shape) < 4: \n",
    "        X = X.reshape(-1, 28, 28, 1)\n",
    "    x = tf.placeholder(\"float\", [None, n,n,1])\n",
    "    y = tf.placeholder(\"float\", [None, n_classes])\n",
    "    \n",
    "    pred = Model(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "    \n",
    "    num_correct = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(num_correct, tf.float32))\n",
    "    saver = tf.train.Saver()\n",
    "    train_loss = []\n",
    "    train_accuracy = []\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    batchLen = len(X) // batch_sz\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    for i in tqdm(range(num_epochs)):\n",
    "        for j in range(batchLen):\n",
    "            batch_X = X[j*batch_sz:min((j+1)*batch_sz,len(X))]\n",
    "            batch_Y = Y[j*batch_sz:min((j+1)*batch_sz,len(Y))]\n",
    "\n",
    "            opt = sess.run(optimizer, feed_dict={x: batch_X,y: batch_Y})\n",
    "            loss,acc = sess.run([cost, accuracy], feed_dict={x: batch_X,y: batch_Y})\n",
    "        train_loss.append(loss)\n",
    "        train_accuracy.append(acc)\n",
    "        print(\"Epoch: {}, Loss: {}, Accuracy: {}\".format(i + 1,loss,acc))\n",
    "    save_path = saver.save(sess, \"./model.ckpt\")\n",
    "    return train_loss,train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(Model,test_X,test_Y):\n",
    "#     tf.reset_default_graph()\n",
    "    if len(test_X.shape) < 4: \n",
    "        test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "    x = tf.placeholder(\"float\", [None, n,n,1])\n",
    "    y = tf.placeholder(\"float\", [None, n_classes])\n",
    "    pred = Model(x)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "    num_correct = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    \n",
    "    accuracy = tf.reduce_mean(tf.cast(num_correct, tf.float32))\n",
    "    saver = tf.train.Saver()\n",
    "    test_loss = []\n",
    "    test_accuracy = []\n",
    "#     init = tf.initialize_all_variables()\n",
    "#     sess.run(init)\n",
    "    test_loss,test_acc = sess.run([cost,accuracy], feed_dict={x: test_X,y : test_Y})\n",
    "    saver.restore(sess, \"./model.ckpt\")\n",
    "    print(\"Loss: {}, Accuracy: {}\".format(test_loss,test_acc))\n",
    "    return test_loss,test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "    def __init__(self,W,b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "    def conv(self,x,W_i,b_i,s = 1):\n",
    "        x = tf.nn.bias_add(tf.nn.conv2d(x, W_i,[1,s,s,1],padding='SAME'),b_i)\n",
    "        return tf.nn.leaky_relu(x)\n",
    "    def maxpool(self,x):\n",
    "        kernel_sz= [1,2,2,1]\n",
    "        return tf.nn.max_pool(x,kernel_sz,kernel_sz,padding='SAME')\n",
    "    def dense(self,x,W_i,b_i):\n",
    "        return tf.nn.leaky_relu(tf.add(tf.matmul(x,W_i),b_i))\n",
    "    def __call__(self,x):\n",
    "        c0 = self.conv(x, self.W['W_0'], self.b['B_0']) # 28 x 28 x 16\n",
    "        m0 = self.maxpool(c0)\n",
    "        \n",
    "        c1 = self.conv(m0,self.W['W_1'],self.b['B_1']) # 14 x 14 x 64\n",
    "        m1 = self.maxpool(c1)\n",
    "        \n",
    "        c2 = self.conv(m1,self.W['W_2'],self.b['B_2']) # 7 x 7 x 128\n",
    "        m2 = self.maxpool(c2)\n",
    "        \n",
    "        c3 = self.conv(m2,self.W['W_3'],self.b['B_3']) # 4 x 4 x 256\n",
    "        m3 = self.maxpool(c3) # 2 x 2 x 256\n",
    "\n",
    "        d0 = tf.reshape(m3, [-1, self.W['W_4'].get_shape().as_list()[0]]) # (256 x 2 x 2, 1)\n",
    "        d0 = self.dense(d0,self.W['W_4'], self.b['B_4']) # (128, 1)\n",
    "\n",
    "        d1 = self.dense(d0,self.W['W_5'],self.b['B_5']) # (10,1)\n",
    "        return d1 \n",
    "model = CNN(W,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:12,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 2.1018667221069336, Accuracy: 0.28125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:02<00:11,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.8963441848754883, Accuracy: 0.7109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:04<00:09,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.5337953567504883, Accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:05<00:08,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.41034185886383057, Accuracy: 0.859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:07<00:07,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.31386834383010864, Accuracy: 0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:08<00:05,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.30495354533195496, Accuracy: 0.8984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:09<00:04,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.26879584789276123, Accuracy: 0.9296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:11<00:02,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.3514832854270935, Accuracy: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:12<00:01,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.18722420930862427, Accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.1065874993801117, Accuracy: 0.9765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.1018667,\n",
       "  0.8963442,\n",
       "  0.53379536,\n",
       "  0.41034186,\n",
       "  0.31386834,\n",
       "  0.30495355,\n",
       "  0.26879585,\n",
       "  0.3514833,\n",
       "  0.18722421,\n",
       "  0.1065875],\n",
       " [0.28125,\n",
       "  0.7109375,\n",
       "  0.8125,\n",
       "  0.859375,\n",
       "  0.90625,\n",
       "  0.8984375,\n",
       "  0.9296875,\n",
       "  0.875,\n",
       "  0.9375,\n",
       "  0.9765625])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainModel(model,mnist.train.images[:2000],mnist.train.labels[:2000],num_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt\n",
      "Loss: 0.17222943902015686, Accuracy: 0.9473000168800354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.17222944, 0.9473)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testModel(model,mnist.test.images,mnist.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel(model,mnist.train.images,mnist.train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = tf.get_variable(\"v1\", shape=[3], initializer = tf.zeros_initializer)\n",
    "v2 = tf.get_variable(\"v2\", shape=[5], initializer = tf.zeros_initializer)\n",
    "\n",
    "inc_v1 = v1.assign(v1+1)\n",
    "dec_v2 = v2.assign(v2-1)\n",
    "\n",
    "# Add an op to initialize the variables.\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, initialize the variables, do some work, and save the\n",
    "# variables to disk.\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init_op)\n",
    "  # Do some work with the model.\n",
    "  inc_v1.op.run()\n",
    "  dec_v2.op.run()\n",
    "  # Save the variables to disk.\n",
    "  save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "  print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", shape=[3])\n",
    "v2 = tf.get_variable(\"v2\", shape=[5])\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "  saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "  print(\"Model restored.\")\n",
    "  # Check the values of the variables\n",
    "  print(\"v1 : %s\" % v1.eval())\n",
    "  print(\"v2 : %s\" % v2.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (verkada)",
   "language": "python",
   "name": "verkada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
